{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":699},"id":"ae8B3SjMQupp","outputId":"6098cd4a-ec16-49f0-aa3e-756ad72c0c26","executionInfo":{"status":"error","timestamp":1698949018806,"user_tz":-60,"elapsed":257315,"user":{"displayName":"Fabio Marme","userId":"11349961017932536629"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(3507, 1)\n","(3507, 1)\n","(3507, 1)\n","(3507, 1)\n","(3507,)\n","Number of parameters:  726\n","Epoch 200 Train 25.47386 Valid 23.45831\n","Epoch 400 Train 7.31437 Valid 7.09488\n","Epoch 600 Train 4.94792 Valid 5.70738\n","Epoch 800 Train 3.91625 Valid 4.06811\n","Epoch 1000 Train 3.76378 Valid 3.86752\n","Epoch 1200 Train 3.72662 Valid 3.85347\n","Epoch 1400 Train 3.71680 Valid 3.83733\n","Epoch 1600 Train 3.71362 Valid 3.83261\n","Epoch 1800 Train 3.71115 Valid 3.83299\n","Epoch 2000 Train 3.71005 Valid 3.83279\n","Epoch 2200 Train 3.71061 Valid 3.83285\n","Epoch 2400 Train 3.71195 Valid 3.83284\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-6e78317a6073>\u001b[0m in \u001b[0;36m<cell line: 216>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-6e78317a6073>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3328\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3329\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","from torch import Tensor\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import random\n","import numpy as np\n","import json\n","import math\n","import matplotlib.pyplot as plt\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # Define a fully connected layers model with three inputs (frequency, flux density, duty ratio) and one output (core loss).\n","        self.layers = nn.Sequential(\n","            nn.Linear(4, 15),\n","            nn.ReLU(),\n","            nn.Linear(15, 20),\n","            nn.ReLU(),\n","            nn.Linear(20, 15),\n","            nn.ReLU(),\n","            nn.Linear(15, 1),\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","def get_dataset():\n","    # Load .json Files\n","    with open('/content/Dataset_tri_77.json','r') as load_f:\n","        DATA = json.load(load_f)\n","\n","    Freq = DATA['Frequency']\n","    Flux = DATA['Flux_Density']\n","    Duty = DATA['Duty_Ratio']\n","    Temperature = DATA['Temperature']\n","    Power = DATA['Power_Loss']\n","\n","    # Compute labels\n","    # There's approximalely an exponential relationship between Loss-Freq and Loss-Flux.\n","    # Using logarithm may help to improve the training.\n","    Freq = np.log10(Freq)\n","    Flux = np.log10(Flux)\n","    Duty = np.array(Duty)\n","    Temperature = np.array(Temperature)\n","    Power = np.log10(Power)\n","\n","    # Reshape data\n","    Freq = Freq.reshape((-1,1))\n","    Flux = Flux.reshape((-1,1))\n","    Duty = Duty.reshape((-1,1))\n","    Temperature = Temperature.reshape((-1,1))\n","\n","    print(np.shape(Freq))\n","    print(np.shape(Flux))\n","    print(np.shape(Duty))\n","    print(np.shape(Temperature))\n","    print(np.shape(Power))\n","\n","    temp = np.concatenate((Freq,Flux,Duty, Temperature),axis=1) #Temperature\n","\n","    in_tensors = torch.from_numpy(temp).view(-1, 4)\n","    out_tensors = torch.from_numpy(Power).view(-1, 1)\n","\n","    # # Save dataset for future use\n","    # np.save(\"dataset.fc.in.npy\", in_tensors.numpy())\n","    # np.save(\"dataset.fc.out.npy\", out_tensors.numpy())\n","\n","    return torch.utils.data.TensorDataset(in_tensors, out_tensors)\n","\n","def get_test():\n","    with open('/content/Dataset_tri_77_pretest.json','r') as load_test:\n","        DATA_TEST = json.load(load_test)\n","\n","    Freq_t = DATA_TEST['Frequency']\n","    Flux_t = DATA_TEST['Flux_Density']\n","    Duty_t = DATA_TEST['Duty_Ratio']\n","    Temperature_t = DATA_TEST['Temperature']\n","    Power_t = DATA_TEST['Power_Loss']\n","\n","    # Compute labels\n","    # There's approximalely an exponential relationship between Loss-Freq and Loss-Flux.\n","    # Using logarithm may help to improve the training.\n","    Freq_t = np.log10(Freq_t)\n","    Flux_t = np.log10(Flux_t)\n","    Duty_t = np.array(Duty_t)\n","    Temperature_t = np.array(Temperature_t)\n","    Power_t = np.log10(Power_t)\n","\n","    # Reshape data\n","    Freq_t = Freq_t.reshape((-1,1))\n","    Flux_t = Flux_t.reshape((-1,1))\n","    Duty_t = Duty_t.reshape((-1,1))\n","    Temperature_t = Temperature_t.reshape((-1,1))\n","\n","    tmp = np.concatenate((Freq_t, Flux_t, Duty_t, Temperature_t),axis=1)\n","\n","    in_tensors = torch.from_numpy(tmp).view(-1, 4)\n","    out_tensors = torch.from_numpy(Power_t).view(-1, 1)\n","\n","    return torch.utils.data.TensorDataset(in_tensors, out_tensors)\n","\n","\n","def main():\n","    # Reproducibility\n","    random.seed(1)\n","    np.random.seed(1)\n","    torch.manual_seed(1)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    # Hyperparameters\n","    NUM_EPOCH = 5000\n","    BATCH_SIZE = 64\n","    DECAY_EPOCH = 100\n","    DECAY_RATIO = 0.5\n","    LR_INI = 0.02\n","\n","    # Select GPU as default device\n","    device = torch.device(\"cuda\")\n","\n","    # Load dataset\n","    dataset = get_dataset()\n","    testing = get_test()\n","\n","    # Split the dataset\n","    train_size = int(0.8 * len(dataset))\n","    valid_size = len(dataset)-train_size\n","    test_size = int(len(testing))\n","    train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n","    test_dataset = testing\n","    kwargs = {'num_workers': 0, 'pin_memory': True, 'pin_memory_device': \"cuda\"}\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n","    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n","\n","    # Setup network\n","    net = Net().double().to(device)\n","\n","    # Log the number of parameters\n","    print(\"Number of parameters: \", count_parameters(net))\n","\n","    # Setup optimizer\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(net.parameters(), lr=LR_INI)\n","\n","    # Train the network\n","    for epoch_i in range(NUM_EPOCH):\n","\n","        # Train for one epoch\n","        epoch_train_loss = 0\n","        net.train()\n","        optimizer.param_groups[0]['lr'] = LR_INI* (DECAY_RATIO ** (0+ epoch_i // DECAY_EPOCH))\n","\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = net(inputs.to(device))\n","            loss = criterion(outputs, labels.to(device))\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_train_loss += loss.item()\n","\n","        # Compute Validation Loss\n","        with torch.no_grad():\n","            epoch_valid_loss = 0\n","            for inputs, labels in valid_loader:\n","                outputs = net(inputs.to(device))\n","                loss = criterion(outputs, labels.to(device))\n","\n","                epoch_valid_loss += loss.item()\n","\n","        if (epoch_i+1)%200 == 0:\n","          print(f\"Epoch {epoch_i+1:2d} \"\n","              f\"Train {epoch_train_loss / len(train_dataset) * 1e5:.5f} \"\n","              f\"Valid {epoch_valid_loss / len(valid_dataset) * 1e5:.5f}\")\n","\n","    # Save the model parameters\n","    torch.save(net.state_dict(), \"/Model_FNN.sd\")\n","    print(\"Training finished! Model is saved!\")\n","\n","\n","    # Evaluation\n","    net.eval()\n","    y_meas = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            y_pred.append(net(inputs.to(device)))\n","            y_meas.append(labels.to(device))\n","\n","    y_meas = torch.cat(y_meas, dim=0)\n","    y_pred = torch.cat(y_pred, dim=0)\n","    print(f\"Test Loss: {F.mse_loss(y_meas, y_pred).item() / len(test_dataset) * 1e5:.5f}\")\n","\n","    yy_pred = 10**(y_pred.cpu().numpy())\n","    yy_meas = 10**(y_meas.cpu().numpy())\n","\n","    # Relative Error\n","    Error_re = abs(yy_pred-yy_meas)/abs(yy_meas)*100\n","    Error_re_avg = np.mean(Error_re)\n","    Error_re_rms = np.sqrt(np.mean(Error_re ** 2))\n","    Error_re_max = np.max(Error_re)\n","    print(f\"Relative Error: {Error_re_avg:.8f}\")\n","    print(f\"RMS Error: {Error_re_rms:.8f}\")\n","    print(f\"MAX Error: {Error_re_max:.8f}\")\n","    plt.hist(Error_re)\n","    plt.show()\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}]}