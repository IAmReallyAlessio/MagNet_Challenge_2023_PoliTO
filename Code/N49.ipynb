{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "ae8B3SjMQupp",
        "outputId": "432a1535-c244-45cc-98eb-d9a07e4745b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2797, 1)\n",
            "(2797, 1)\n",
            "(2797, 1)\n",
            "(2797, 1)\n",
            "(2797,)\n",
            "Number of parameters:  726\n",
            "Epoch 200 Train 38.19430 Valid 24.24090\n",
            "Epoch 400 Train 19.78877 Valid 20.08496\n",
            "Epoch 600 Train 16.49011 Valid 17.00977\n",
            "Epoch 800 Train 5.95472 Valid 7.27697\n",
            "Epoch 1000 Train 4.78069 Valid 5.35887\n",
            "Epoch 1200 Train 4.01466 Valid 4.67177\n",
            "Epoch 1400 Train 3.95314 Valid 4.69079\n",
            "Epoch 1600 Train 3.61709 Valid 4.58218\n",
            "Epoch 1800 Train 3.82105 Valid 4.17097\n",
            "Epoch 2000 Train 3.53659 Valid 4.04611\n",
            "Training finished! Model is saved!\n",
            "Test Loss: 0.20158\n",
            "Relative Error: 9.97601802\n",
            "RMS Error: 13.06104867\n",
            "MAX Error: 50.87686636\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Define a fully connected layers model with three inputs (frequency, flux density, duty ratio) and one output (core loss).\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(4, 15),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(15, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 15),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(15, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def get_dataset():\n",
        "    # Load .json Files\n",
        "    with open('/Dataset_tri_N49.json','r') as load_f:\n",
        "        DATA = json.load(load_f)\n",
        "\n",
        "    Freq = DATA['Frequency']\n",
        "    Flux = DATA['Flux_Density']\n",
        "    Duty = DATA['Duty_Ratio']\n",
        "    Temperature = DATA['Temperature']\n",
        "    Power = DATA['Power_Loss']\n",
        "\n",
        "    # Compute labels\n",
        "    # There's approximalely an exponential relationship between Loss-Freq and Loss-Flux.\n",
        "    # Using logarithm may help to improve the training.\n",
        "    Freq = np.log10(Freq)\n",
        "    Flux = np.log10(Flux)\n",
        "    Duty = np.array(Duty)\n",
        "    Temperature = np.array(Temperature)\n",
        "    Power = np.log10(Power)\n",
        "\n",
        "    # Reshape data\n",
        "    Freq = Freq.reshape((-1,1))\n",
        "    Flux = Flux.reshape((-1,1))\n",
        "    Duty = Duty.reshape((-1,1))\n",
        "    Temperature = Temperature.reshape((-1,1))\n",
        "\n",
        "    print(np.shape(Freq))\n",
        "    print(np.shape(Flux))\n",
        "    print(np.shape(Duty))\n",
        "    print(np.shape(Temperature))\n",
        "    print(np.shape(Power))\n",
        "\n",
        "    temp = np.concatenate((Freq,Flux,Duty, Temperature),axis=1) #Temperature\n",
        "\n",
        "    in_tensors = torch.from_numpy(temp).view(-1, 4)\n",
        "    out_tensors = torch.from_numpy(Power).view(-1, 1)\n",
        "\n",
        "    # # Save dataset for future use\n",
        "    # np.save(\"dataset.fc.in.npy\", in_tensors.numpy())\n",
        "    # np.save(\"dataset.fc.out.npy\", out_tensors.numpy())\n",
        "\n",
        "    return torch.utils.data.TensorDataset(in_tensors, out_tensors)\n",
        "\n",
        "def get_test():\n",
        "    with open('/Dataset_tri_N49_pretest.json','r') as load_test:\n",
        "        DATA_TEST = json.load(load_test)\n",
        "\n",
        "    Freq_t = DATA_TEST['Frequency']\n",
        "    Flux_t = DATA_TEST['Flux_Density']\n",
        "    Duty_t = DATA_TEST['Duty_Ratio']\n",
        "    Temperature_t = DATA_TEST['Temperature']\n",
        "    Power_t = DATA_TEST['Power_Loss']\n",
        "\n",
        "    # Compute labels\n",
        "    # There's approximalely an exponential relationship between Loss-Freq and Loss-Flux.\n",
        "    # Using logarithm may help to improve the training.\n",
        "    Freq_t = np.log10(Freq_t)\n",
        "    Flux_t = np.log10(Flux_t)\n",
        "    Duty_t = np.array(Duty_t)\n",
        "    Temperature_t = np.array(Temperature_t)\n",
        "    Power_t = np.log10(Power_t)\n",
        "\n",
        "    # Reshape data\n",
        "    Freq_t = Freq_t.reshape((-1,1))\n",
        "    Flux_t = Flux_t.reshape((-1,1))\n",
        "    Duty_t = Duty_t.reshape((-1,1))\n",
        "    Temperature_t = Temperature_t.reshape((-1,1))\n",
        "\n",
        "    tmp = np.concatenate((Freq_t, Flux_t, Duty_t, Temperature_t),axis=1)\n",
        "\n",
        "    in_tensors = torch.from_numpy(tmp).view(-1, 4)\n",
        "    out_tensors = torch.from_numpy(Power_t).view(-1, 1)\n",
        "\n",
        "    return torch.utils.data.TensorDataset(in_tensors, out_tensors)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Reproducibility\n",
        "    random.seed(1)\n",
        "    np.random.seed(1)\n",
        "    torch.manual_seed(1)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # Hyperparameters\n",
        "    NUM_EPOCH = 2000\n",
        "    BATCH_SIZE = 64\n",
        "    DECAY_EPOCH = 200\n",
        "    DECAY_RATIO = 0.55\n",
        "    LR_INI = 0.02\n",
        "\n",
        "    # Select GPU as default device\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    # Load dataset\n",
        "    dataset = get_dataset()\n",
        "    testing = get_test()\n",
        "\n",
        "    # Split the dataset\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    valid_size = len(dataset)-train_size\n",
        "    test_size = int(len(testing))\n",
        "    train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "    test_dataset = testing\n",
        "    kwargs = {'num_workers': 0, 'pin_memory': True, 'pin_memory_device': \"cuda\"}\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
        "\n",
        "    # Setup network\n",
        "    net = Net().double().to(device)\n",
        "\n",
        "    # Log the number of parameters\n",
        "    print(\"Number of parameters: \", count_parameters(net))\n",
        "\n",
        "    # Setup optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=LR_INI)\n",
        "\n",
        "    # Train the network\n",
        "    for epoch_i in range(NUM_EPOCH):\n",
        "\n",
        "        # Train for one epoch\n",
        "        epoch_train_loss = 0\n",
        "        net.train()\n",
        "        optimizer.param_groups[0]['lr'] = LR_INI* (DECAY_RATIO ** (0+ epoch_i // DECAY_EPOCH))\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs.to(device))\n",
        "            loss = criterion(outputs, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "        # Compute Validation Loss\n",
        "        with torch.no_grad():\n",
        "            epoch_valid_loss = 0\n",
        "            for inputs, labels in valid_loader:\n",
        "                outputs = net(inputs.to(device))\n",
        "                loss = criterion(outputs, labels.to(device))\n",
        "\n",
        "                epoch_valid_loss += loss.item()\n",
        "\n",
        "        if (epoch_i+1)%200 == 0:\n",
        "          print(f\"Epoch {epoch_i+1:2d} \"\n",
        "              f\"Train {epoch_train_loss / len(train_dataset) * 1e5:.5f} \"\n",
        "              f\"Valid {epoch_valid_loss / len(valid_dataset) * 1e5:.5f}\")\n",
        "\n",
        "    # Save the model parameters\n",
        "    torch.save(net.state_dict(), \"/Model_FNN.sd\")\n",
        "    print(\"Training finished! Model is saved!\")\n",
        "\n",
        "\n",
        "    # Evaluation\n",
        "    net.eval()\n",
        "    y_meas = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            y_pred.append(net(inputs.to(device)))\n",
        "            y_meas.append(labels.to(device))\n",
        "\n",
        "    y_meas = torch.cat(y_meas, dim=0)\n",
        "    y_pred = torch.cat(y_pred, dim=0)\n",
        "    print(f\"Test Loss: {F.mse_loss(y_meas, y_pred).item() / len(test_dataset) * 1e5:.5f}\")\n",
        "\n",
        "    yy_pred = 10**(y_pred.cpu().numpy())\n",
        "    yy_meas = 10**(y_meas.cpu().numpy())\n",
        "\n",
        "    # Relative Error\n",
        "    Error_re = abs(yy_pred-yy_meas)/abs(yy_meas)*100\n",
        "    Error_re_avg = np.mean(Error_re)\n",
        "    Error_re_rms = np.sqrt(np.mean(Error_re ** 2))\n",
        "    Error_re_max = np.max(Error_re)\n",
        "    print(f\"Relative Error: {Error_re_avg:.8f}\")\n",
        "    print(f\"RMS Error: {Error_re_rms:.8f}\")\n",
        "    print(f\"MAX Error: {Error_re_max:.8f}\")\n",
        "    plt.hist(Error_re, bins = 30)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}