{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install bayesian-optimization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mlyVoukHUhp2","executionInfo":{"status":"ok","timestamp":1700394882511,"user_tz":-60,"elapsed":4638,"user":{"displayName":"Fabio Marme","userId":"11349961017932536629"}},"outputId":"3b9fbbb9-7a14-466a-a8f8-0834c80c89b9"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.10/dist-packages (1.4.3)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.23.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.11.3)\n","Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.2.2)\n","Requirement already satisfied: colorama>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (0.4.6)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.2.0)\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"ae8B3SjMQupp","executionInfo":{"status":"error","timestamp":1700394918521,"user_tz":-60,"elapsed":244,"user":{"displayName":"Fabio Marme","userId":"11349961017932536629"}},"outputId":"0eb46c2e-7e68-4f63-b7ed-983c1e2a6711"},"outputs":[{"output_type":"stream","name":"stdout","text":["|   iter    |  target   | decay_... | decay_... |  lr_ini   |\n","-------------------------------------------------------------\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-b790e9dcaaf4>\u001b[0m in \u001b[0;36m<cell line: 230>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-16-b790e9dcaaf4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mpbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"lr_ini\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decay_epoch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decay_ratio\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final result:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-b790e9dcaaf4>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(lr_ini, decay_epoch, decay_ratio)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_ini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mdecay_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecay_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_ini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-b790e9dcaaf4>\u001b[0m in \u001b[0;36m_try_\u001b[0;34m(lr_ini, decay_epoch, decay_ratio)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}],"source":["import torch\n","from torch import Tensor\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import random\n","import numpy as np\n","import json\n","import time\n","import matplotlib.pyplot as plt\n","\n","\n","from bayes_opt import BayesianOptimization\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # Define a fully connected layers model with three inputs (frequency, flux density, duty ratio) and one output (core loss).\n","        self.layers = nn.Sequential(\n","            nn.Linear(4, 17),\n","            nn.Tanh(),\n","            nn.Linear(17, 12),\n","            nn.Tanh(),\n","            nn.Linear(12, 17),\n","            nn.Tanh(),\n","            nn.Linear(17, 1),\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","\n","\n","\n","def get_dataset():\n","    # Load .json Files\n","    with open('/content/Dataset_tri_N87_mod.json','r') as load_f:\n","        DATA = json.load(load_f)\n","\n","    Freq = DATA['Frequency']\n","    Flux = DATA['Flux_Density']\n","    Duty = DATA['Duty_Ratio']\n","    Temperature = DATA['Temperature']\n","    Power = DATA['Power_Loss']\n","\n","    # Compute labels\n","    # There's approximalely an exponential relationship between Loss-Freq and Loss-Flux.\n","    # Using logarithm may help to improve the training.\n","    Freq = np.log10(Freq)\n","    Flux = np.log10(Flux)\n","    Duty = np.array(Duty)\n","    Temperature = np.array(Temperature)\n","    Power = np.log10(Power)\n","\n","    # Reshape data\n","    Freq = Freq.reshape((-1,1))\n","    Flux = Flux.reshape((-1,1))\n","    Duty = Duty.reshape((-1,1))\n","    Temperature = Temperature.reshape((-1,1))\n","\n","    \"\"\" print(np.shape(Freq))\n","    print(np.shape(Flux))\n","    print(np.shape(Duty))\n","    print(np.shape(Temperature))\n","    print(np.shape(Power)) \"\"\"\n","\n","    temp = np.concatenate((Freq, Flux, Duty, Temperature),axis=1)\n","\n","    in_tensors = torch.from_numpy(temp).view(-1, 4)\n","    out_tensors = torch.from_numpy(Power).view(-1, 1)\n","\n","    # # Save dataset for future use\n","    # np.save(\"dataset.fc.in.npy\", in_tensors.numpy())\n","    # np.save(\"dataset.fc.out.npy\", out_tensors.numpy())\n","\n","    return torch.utils.data.TensorDataset(in_tensors, out_tensors)\n","\n","\n","def _try_(lr_ini, decay_epoch, decay_ratio):\n","    # Reproducibility\n","    random.seed(2)\n","    np.random.seed(2)\n","    torch.manual_seed(2)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    # Hyperparameters\n","    NUM_EPOCH = 1000\n","    BATCH_SIZE = 128\n","    DECAY_EPOCH = decay_epoch\n","    DECAY_RATIO = decay_ratio\n","    LR_INI = lr_ini\n","\n","    # Select GPU as default device\n","    device = torch.device(\"cuda\")\n","\n","    # Get dataset\n","    dataset = get_dataset()\n","\n","    splits = torch.utils.data.random_split(dataset, [0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.2])\n","\n","    # Split the dataset\n","    kwargs = {'num_workers': 0, 'pin_memory': True, 'pin_memory_device': \"cuda\"}\n","\n","    test_loader = torch.utils.data.DataLoader(splits[8], batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n","    test_size = len(splits[8])\n","\n","    # Setup network\n","    net = Net().double().to(device)\n","\n","    # Log the number of parameters\n","    #print(\"Number of parameters: \", count_parameters(net))\n","\n","    # Setup optimizer\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(net.parameters(), lr=LR_INI)\n","\n","    # Setup values for plot of loss function\n","    y_costf = []\n","    y_validf = []\n","    epochs = []\n","\n","\n","    # Train the network\n","    #print(\"Starting Training:\")\n","\n","    for epoch_i in range(NUM_EPOCH):\n","        rnd = random.randint(0,7)\n","        valid_loader = torch.utils.data.DataLoader(splits[rnd], batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n","        valid_size = len(splits[rnd])\n","        train_size = 0\n","        train_loader = []\n","        for i in range(0,8):\n","            if i!=rnd:\n","                train_loader = torch.utils.data.ConcatDataset([train_loader, splits[i]])\n","                train_size += len(splits[i])\n","\n","        train_loader = torch.utils.data.DataLoader(train_loader, batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n","        # Train for one epoch\n","        epoch_train_loss = 0\n","        net.train()\n","        optimizer.param_groups[0]['lr'] = LR_INI* (DECAY_RATIO ** (0+ epoch_i // DECAY_EPOCH))\n","\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = net(inputs.to(device))\n","            loss = criterion(outputs, labels.to(device))\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_train_loss += loss.item()\n","\n","        # Compute Validation Loss\n","        with torch.no_grad():\n","            epoch_valid_loss = 0\n","            for inputs, labels in valid_loader:\n","                outputs = net(inputs.to(device))\n","                loss = criterion(outputs, labels.to(device))\n","\n","                epoch_valid_loss += loss.item()\n","\n","        # Progress Bar\n","        if (epoch_i+1)%10 == 0:\n","          #print(\".\", end=\"\", flush=True)\n","          epochs.append(epoch_i)\n","          y_costf.append(epoch_train_loss / train_size * 1e5)\n","          y_validf.append(epoch_valid_loss / valid_size * 1e5)\n","\n","    # Save the model parameters\n","    #torch.save(net.state_dict(), \"/content/Model_FNN.sd\")\n","    #print(\"Training finished! Model is saved!\")\n","\n","    # Evaluation\n","    net.eval()\n","    y_meas = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            y_pred.append(net(inputs.to(device)))\n","            y_meas.append(labels.to(device))\n","\n","    y_meas = torch.cat(y_meas, dim=0)\n","    y_pred = torch.cat(y_pred, dim=0)\n","    test_loss = F.mse_loss(y_meas, y_pred).item() / test_size * 1e5\n","#    print(f\"Test Loss: {F.mse_loss(y_meas, y_pred).item() / test_size * 1e5:.5f}\")\n","\n","    yy_pred = 10**(y_pred.cpu().numpy())\n","    yy_meas = 10**(y_meas.cpu().numpy())\n","\n","    # Relative Error\n","    Error_re = abs(yy_pred-yy_meas)/abs(yy_meas)*100\n","    Error_re_avg = np.mean(Error_re)\n","    Error_re_rms = np.sqrt(np.mean(Error_re ** 2))\n","    Error_re_max = np.max(Error_re)\n","#    print(f\"Relative Error: {Error_re_avg:.8f}\")\n","#    print(f\"RMS Error: {Error_re_rms:.8f}\")\n","#    print(f\"MAX Error: {Error_re_max:.8f}\")\n","\n","    #Save plot of loss functions\n","    plt.figure(figsize=(15,10))\n","    plt.plot(epochs,y_costf)\n","    plt.plot(epochs,y_validf)\n","    plt.legend([\"Train_Loss\", \"Valid_Loss\"])\n","    plt.grid()\n","    plt.savefig(f\"/content/Bayes_opti_N87/tentativo_{lr_ini}_{decay_epoch}_{decay_ratio}.png\")\n","    plt.close()\n","\n","    return test_loss\n","\n","\n","def wrapper(lr_ini, decay_epoch, decay_ratio):\n","    decay_epoch = round(decay_epoch)\n","    result = _try_(lr_ini, decay_epoch, decay_ratio)\n","    return 1/result\n","\n","\n","def main():\n","    bo = BayesianOptimization(\n","        f = wrapper,\n","        pbounds = {\"lr_ini\": (0.005, 0.05), \"decay_epoch\": (50, 200), \"decay_ratio\": (0.3, 0.7)}\n","    )\n","    bo.maximize(init_points = 40, n_iter = 50)\n","\n","    print(\"Final result:\", bo.max)\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}]}