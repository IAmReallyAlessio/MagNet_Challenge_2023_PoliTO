{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "ae8B3SjMQupp",
        "outputId": "e60ecf62-bc03-4c04-ef4e-4f46ede8d66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13189, 1)\n",
            "(13189, 1)\n",
            "(13189, 1)\n",
            "(13189, 1)\n",
            "(13189,)\n",
            "Number of parameters:  726\n",
            "Epoch 200 Train 4.21418 Valid 3.66683\n",
            "Epoch 400 Train 2.30882 Valid 2.09516\n",
            "Epoch 600 Train 1.99584 Valid 2.09543\n",
            "Epoch 800 Train 1.83723 Valid 2.15263\n",
            "Epoch 1000 Train 1.80483 Valid 1.93654\n",
            "Training finished! Model is saved!\n",
            "Test Loss: 0.07445\n",
            "Relative Error: 6.25624585\n",
            "RMS Error: 7.87020403\n",
            "MAX Error: 30.31688478\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Define a fully connected layers model with three inputs (frequency, flux density, duty ratio) and one output (core loss).\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(4, 15),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(15, 20),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 15),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(15, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def get_dataset():\n",
        "    # Load .json Files\n",
        "    with open('/Dataset_tri_N87.json','r') as load_f:\n",
        "        DATA = json.load(load_f)\n",
        "\n",
        "    Freq = DATA['Frequency']\n",
        "    Flux = DATA['Flux_Density']\n",
        "    Duty = DATA['Duty_Ratio']\n",
        "    Temperature = DATA['Temperature']\n",
        "    Power = DATA['Power_Loss']\n",
        "\n",
        "    # Compute labels\n",
        "    # There's approximalely an exponential relationship between Loss-Freq and Loss-Flux.\n",
        "    # Using logarithm may help to improve the training.\n",
        "    Freq = np.log10(Freq)\n",
        "    Flux = np.log10(Flux)\n",
        "    Duty = np.array(Duty)\n",
        "    Temperature = np.array(Temperature)\n",
        "    Power = np.log10(Power)\n",
        "\n",
        "    # Reshape data\n",
        "    Freq = Freq.reshape((-1,1))\n",
        "    Flux = Flux.reshape((-1,1))\n",
        "    Duty = Duty.reshape((-1,1))\n",
        "    Temperature = Temperature.reshape((-1,1))\n",
        "\n",
        "    print(np.shape(Freq))\n",
        "    print(np.shape(Flux))\n",
        "    print(np.shape(Duty))\n",
        "    print(np.shape(Temperature))\n",
        "    print(np.shape(Power))\n",
        "\n",
        "    temp = np.concatenate((Freq,Flux,Duty, Temperature),axis=1) #Temperature\n",
        "\n",
        "    in_tensors = torch.from_numpy(temp).view(-1, 4)\n",
        "    out_tensors = torch.from_numpy(Power).view(-1, 1)\n",
        "\n",
        "    # # Save dataset for future use\n",
        "    # np.save(\"dataset.fc.in.npy\", in_tensors.numpy())\n",
        "    # np.save(\"dataset.fc.out.npy\", out_tensors.numpy())\n",
        "\n",
        "    return torch.utils.data.TensorDataset(in_tensors, out_tensors)\n",
        "\n",
        "def get_test():\n",
        "    with open('/Dataset_tri_N87_pretest.json','r') as load_test:\n",
        "        DATA_TEST = json.load(load_test)\n",
        "\n",
        "    Freq_t = DATA_TEST['Frequency']\n",
        "    Flux_t = DATA_TEST['Flux_Density']\n",
        "    Duty_t = DATA_TEST['Duty_Ratio']\n",
        "    Temperature_t = DATA_TEST['Temperature']\n",
        "    Power_t = DATA_TEST['Power_Loss']\n",
        "\n",
        "    # Compute labels\n",
        "    # There's approximalely an exponential relationship between Loss-Freq and Loss-Flux.\n",
        "    # Using logarithm may help to improve the training.\n",
        "    Freq_t = np.log10(Freq_t)\n",
        "    Flux_t = np.log10(Flux_t)\n",
        "    Duty_t = np.array(Duty_t)\n",
        "    Temperature_t = np.array(Temperature_t)\n",
        "    Power_t = np.log10(Power_t)\n",
        "\n",
        "    # Reshape data\n",
        "    Freq_t = Freq_t.reshape((-1,1))\n",
        "    Flux_t = Flux_t.reshape((-1,1))\n",
        "    Duty_t = Duty_t.reshape((-1,1))\n",
        "    Temperature_t = Temperature_t.reshape((-1,1))\n",
        "\n",
        "    tmp = np.concatenate((Freq_t, Flux_t, Duty_t, Temperature_t),axis=1)\n",
        "\n",
        "    in_tensors = torch.from_numpy(tmp).view(-1, 4)\n",
        "    out_tensors = torch.from_numpy(Power_t).view(-1, 1)\n",
        "\n",
        "    return torch.utils.data.TensorDataset(in_tensors, out_tensors)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Reproducibility\n",
        "    random.seed(1)\n",
        "    np.random.seed(1)\n",
        "    torch.manual_seed(1)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # Hyperparameters\n",
        "    NUM_EPOCH = 1000\n",
        "    BATCH_SIZE = 64\n",
        "    DECAY_EPOCH = 100\n",
        "    DECAY_RATIO = 0.5\n",
        "    LR_INI = 0.02\n",
        "\n",
        "    # Select GPU as default device\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    # Load dataset\n",
        "    dataset = get_dataset()\n",
        "    testing = get_test()\n",
        "\n",
        "    # Split the dataset\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    valid_size = len(dataset)-train_size\n",
        "    test_size = int(len(testing))\n",
        "    train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "    test_dataset = testing\n",
        "    kwargs = {'num_workers': 0, 'pin_memory': True, 'pin_memory_device': \"cuda\"}\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
        "\n",
        "    # Setup network\n",
        "    net = Net().double().to(device)\n",
        "\n",
        "    # Log the number of parameters\n",
        "    print(\"Number of parameters: \", count_parameters(net))\n",
        "\n",
        "    # Setup optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=LR_INI)\n",
        "\n",
        "    # Train the network\n",
        "    for epoch_i in range(NUM_EPOCH):\n",
        "\n",
        "        # Train for one epoch\n",
        "        epoch_train_loss = 0\n",
        "        net.train()\n",
        "        optimizer.param_groups[0]['lr'] = LR_INI* (DECAY_RATIO ** (0+ epoch_i // DECAY_EPOCH))\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs.to(device))\n",
        "            loss = criterion(outputs, labels.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_train_loss += loss.item()\n",
        "\n",
        "        # Compute Validation Loss\n",
        "        with torch.no_grad():\n",
        "            epoch_valid_loss = 0\n",
        "            for inputs, labels in valid_loader:\n",
        "                outputs = net(inputs.to(device))\n",
        "                loss = criterion(outputs, labels.to(device))\n",
        "\n",
        "                epoch_valid_loss += loss.item()\n",
        "\n",
        "        if (epoch_i+1)%200 == 0:\n",
        "          print(f\"Epoch {epoch_i+1:2d} \"\n",
        "              f\"Train {epoch_train_loss / len(train_dataset) * 1e5:.5f} \"\n",
        "              f\"Valid {epoch_valid_loss / len(valid_dataset) * 1e5:.5f}\")\n",
        "\n",
        "    # Save the model parameters\n",
        "    torch.save(net.state_dict(), \"/Model_FNN.sd\")\n",
        "    print(\"Training finished! Model is saved!\")\n",
        "\n",
        "\n",
        "    # Evaluation\n",
        "    net.eval()\n",
        "    y_meas = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            y_pred.append(net(inputs.to(device)))\n",
        "            y_meas.append(labels.to(device))\n",
        "\n",
        "    y_meas = torch.cat(y_meas, dim=0)\n",
        "    y_pred = torch.cat(y_pred, dim=0)\n",
        "    print(f\"Test Loss: {F.mse_loss(y_meas, y_pred).item() / len(test_dataset) * 1e5:.5f}\")\n",
        "\n",
        "    yy_pred = 10**(y_pred.cpu().numpy())\n",
        "    yy_meas = 10**(y_meas.cpu().numpy())\n",
        "\n",
        "    # Relative Error\n",
        "    Error_re = abs(yy_pred-yy_meas)/abs(yy_meas)*100\n",
        "    Error_re_avg = np.mean(Error_re)\n",
        "    Error_re_rms = np.sqrt(np.mean(Error_re ** 2))\n",
        "    Error_re_max = np.max(Error_re)\n",
        "    print(f\"Relative Error: {Error_re_avg:.8f}\")\n",
        "    print(f\"RMS Error: {Error_re_rms:.8f}\")\n",
        "    print(f\"MAX Error: {Error_re_max:.8f}\")\n",
        "    plt.hist(Error_re)\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}